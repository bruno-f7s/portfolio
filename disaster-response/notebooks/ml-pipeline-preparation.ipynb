{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "This notebook was used set up the ml pipeline of the disaster recovery project and to get choose the best model and parameter settings based on the results from the grid search. The final model will be created in the python script train_classifier.py file, which is located [here]().\n",
    "\n",
    "Therefore this notebook is not necessary for launching the app, but can be revisited if a new dataset needs to be used to train a new model.\n",
    "\n",
    "The code below is divided into the following steps:\n",
    "1. Import libraries\n",
    "2. Load and prepare the data\n",
    "3. Define NLP processing functions\n",
    "5. Build and run a machine learning pipeline\n",
    "6. Model choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bfernandes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "nltk.download(['wordnet'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "conn = sqlite3.connect('DisasterResponse.db')\n",
    "query = \"SELECT * FROM DisasterResponse\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# remove rows which do not have any label as they will not provide any prediction\n",
    "label_cols = df.drop([\"id\",\"message\",\"original\",\"genre\"], axis=1).columns\n",
    "df['sum'] = df[label_cols].sum(axis=1)\n",
    "df = df[df['sum'] != 0]\n",
    "df = df.drop([\"sum\"], axis=1)\n",
    "\n",
    "# create X and y variables\n",
    "X = df[\"message\"]\n",
    "y = df.drop([\"id\",\"message\",\"original\",\"genre\"], axis=1)\n",
    "\n",
    "# create the train and test splits\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X.values, y.values, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: related\n",
      "Percentage of 0s: 0.0%\n",
      "Percentage of 1s: 100.0%\n",
      "---------------------\n",
      "Label: request\n",
      "Percentage of 0s: 77.7%\n",
      "Percentage of 1s: 22.3%\n",
      "---------------------\n",
      "Label: offer\n",
      "Percentage of 0s: 99.4%\n",
      "Percentage of 1s: 0.6%\n",
      "---------------------\n",
      "Label: aid_related\n",
      "Percentage of 0s: 45.9%\n",
      "Percentage of 1s: 54.1%\n",
      "---------------------\n",
      "Label: medical_help\n",
      "Percentage of 0s: 89.6%\n",
      "Percentage of 1s: 10.4%\n",
      "---------------------\n",
      "Label: medical_products\n",
      "Percentage of 0s: 93.5%\n",
      "Percentage of 1s: 6.5%\n",
      "---------------------\n",
      "Label: search_and_rescue\n",
      "Percentage of 0s: 96.4%\n",
      "Percentage of 1s: 3.6%\n",
      "---------------------\n",
      "Label: security\n",
      "Percentage of 0s: 97.7%\n",
      "Percentage of 1s: 2.3%\n",
      "---------------------\n",
      "Label: military\n",
      "Percentage of 0s: 95.7%\n",
      "Percentage of 1s: 4.3%\n",
      "---------------------\n",
      "Label: child_alone\n",
      "Percentage of 0s: 100.0%\n",
      "Percentage of 1s: 0.0%\n",
      "---------------------\n",
      "Label: water\n",
      "Percentage of 0s: 91.7%\n",
      "Percentage of 1s: 8.3%\n",
      "---------------------\n",
      "Label: food\n",
      "Percentage of 0s: 85.4%\n",
      "Percentage of 1s: 14.6%\n",
      "---------------------\n",
      "Label: shelter\n",
      "Percentage of 0s: 88.5%\n",
      "Percentage of 1s: 11.5%\n",
      "---------------------\n",
      "Label: clothing\n",
      "Percentage of 0s: 98.0%\n",
      "Percentage of 1s: 2.0%\n",
      "---------------------\n",
      "Label: money\n",
      "Percentage of 0s: 97.0%\n",
      "Percentage of 1s: 3.0%\n",
      "---------------------\n",
      "Label: missing_people\n",
      "Percentage of 0s: 98.5%\n",
      "Percentage of 1s: 1.5%\n",
      "---------------------\n",
      "Label: refugees\n",
      "Percentage of 0s: 95.6%\n",
      "Percentage of 1s: 4.4%\n",
      "---------------------\n",
      "Label: death\n",
      "Percentage of 0s: 94.1%\n",
      "Percentage of 1s: 5.9%\n",
      "---------------------\n",
      "Label: other_aid\n",
      "Percentage of 0s: 82.9%\n",
      "Percentage of 1s: 17.1%\n",
      "---------------------\n",
      "Label: infrastructure_related\n",
      "Percentage of 0s: 91.5%\n",
      "Percentage of 1s: 8.5%\n",
      "---------------------\n",
      "Label: transport\n",
      "Percentage of 0s: 94.0%\n",
      "Percentage of 1s: 6.0%\n",
      "---------------------\n",
      "Label: buildings\n",
      "Percentage of 0s: 93.4%\n",
      "Percentage of 1s: 6.6%\n",
      "---------------------\n",
      "Label: electricity\n",
      "Percentage of 0s: 97.3%\n",
      "Percentage of 1s: 2.7%\n",
      "---------------------\n",
      "Label: tools\n",
      "Percentage of 0s: 99.2%\n",
      "Percentage of 1s: 0.8%\n",
      "---------------------\n",
      "Label: hospitals\n",
      "Percentage of 0s: 98.6%\n",
      "Percentage of 1s: 1.4%\n",
      "---------------------\n",
      "Label: shops\n",
      "Percentage of 0s: 99.4%\n",
      "Percentage of 1s: 0.6%\n",
      "---------------------\n",
      "Label: aid_centers\n",
      "Percentage of 0s: 98.5%\n",
      "Percentage of 1s: 1.5%\n",
      "---------------------\n",
      "Label: other_infrastructure\n",
      "Percentage of 0s: 94.3%\n",
      "Percentage of 1s: 5.7%\n",
      "---------------------\n",
      "Label: weather_related\n",
      "Percentage of 0s: 63.7%\n",
      "Percentage of 1s: 36.3%\n",
      "---------------------\n",
      "Label: floods\n",
      "Percentage of 0s: 89.3%\n",
      "Percentage of 1s: 10.7%\n",
      "---------------------\n",
      "Label: storm\n",
      "Percentage of 0s: 87.8%\n",
      "Percentage of 1s: 12.2%\n",
      "---------------------\n",
      "Label: fire\n",
      "Percentage of 0s: 98.6%\n",
      "Percentage of 1s: 1.4%\n",
      "---------------------\n",
      "Label: earthquake\n",
      "Percentage of 0s: 87.8%\n",
      "Percentage of 1s: 12.2%\n",
      "---------------------\n",
      "Label: cold\n",
      "Percentage of 0s: 97.4%\n",
      "Percentage of 1s: 2.6%\n",
      "---------------------\n",
      "Label: other_weather\n",
      "Percentage of 0s: 93.2%\n",
      "Percentage of 1s: 6.8%\n",
      "---------------------\n",
      "Label: direct_report\n",
      "Percentage of 0s: 74.7%\n",
      "Percentage of 1s: 25.3%\n",
      "---------------------\n",
      "Total number of rows: 20106\n"
     ]
    }
   ],
   "source": [
    "# print the distribution of the values for each label\n",
    "for column in label_cols:\n",
    "    print(f\"Label: {column}\")\n",
    "    print(f\"Percentage of 0s: {round((len(y[y[column] == 0])/len(y[column]))*100, 1)}%\")\n",
    "    print(f\"Percentage of 1s: {round((len(y[y[column] == 1])/len(y[column]))*100, 1)}%\")\n",
    "    print(f\"---------------------\")\n",
    "    \n",
    "print(f\"Total number of rows: {len(df)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: In this project a train and validation splits were created __without the holdout set__ (which I typically do) for a few reasons:\n",
    "1. This is a multi-label problem with 36 labels so I decided it was feasible to use directly all the data available because there are some labels which are highly imbalanced and this could lead to many missing data of one category during training.\n",
    "2. The dataset is not that big and creating this holdout set would remove more data from the training processed.\n",
    "3. This code is intended to be used to analyze and decide for the best model but the final model will be created in a different file. Therefore the results of the train/validation splits are sufficient to make a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define NLP processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenize function that processes text data\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function takes in a string, tokenizes it, removes English stop words and applies lemmatization. \n",
    "    The result is a list of all resulting tokens. This function can be passed into a tokenizer of a transformer.\n",
    "    \"\"\"\n",
    "    #tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #stop word removal\n",
    "    tokens = [tok.lower().strip() for tok in tokens if tok not in stopwords.words(\"english\")]\n",
    "\n",
    "    #stemming of words\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(tok) for tok in tokens]\n",
    "\n",
    "    #lemmatization of words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(tok, pos='v') for tok in stemmed_tokens]\n",
    "\n",
    "    #remove tokens that only contain special characters\n",
    "    clean_tokens = [tok for tok in lemmatized_tokens if not re.match(\"^[\\W_]+\", tok)]\n",
    "    \n",
    "    #remove tokens that contain digits as they will not be relevant for this supervised learning problem\n",
    "    clean_tokens = [tok for tok in clean_tokens if not re.search(\"\\d\", tok)]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "['weather', 'updat', 'cold', 'front', 'cuba', 'could', 'pass', 'haiti'] \n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "['be', 'hurrican'] \n",
      "\n",
      "Looking for someone but no name\n",
      "['look', 'someon', 'name'] \n",
      "\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "['un', 'report', 'leogan', 'destroy', 'onli', 'hospit', 'st.', 'croix', 'function', 'need', 'suppli', 'desper'] \n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "['say', 'west', 'side', 'haiti', 'rest', 'countri', 'today', 'tonight'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the results of the tokenize function\n",
    "for message in X[:5]:\n",
    "    tokens = tokenize(message)\n",
    "    print(message)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom transformer to count words\n",
    "class WordCounter:\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [[len(text.split())] for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build and run a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model Logistic Regression using grid search with cross-validation...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:80: UserWarning: Label not 1.0 is present in all training examples.\n",
      "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:80: UserWarning: Label not 0.0 is present in all training examples.\n",
      "  warnings.warn(\"Label %s is present in all training examples.\" %\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# BUILD A ML PIPELINE\n",
    "#########################################################################\n",
    "modelling_start_time = datetime.datetime.now()\n",
    "\n",
    "# Create a dictionary of ml models with their respective hyperparameters\n",
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": MultiOutputClassifier(OneVsRestClassifier(LogisticRegression())),\n",
    "        \"param_grid\": {\n",
    "            'model__estimator__estimator__penalty': ['elasticnet'],\n",
    "            'model__estimator__estimator__l1_ratio': [0, 0.5, 1],\n",
    "            'model__estimator__estimator__C': [0.1, 1, 10],\n",
    "            'model__estimator__estimator__solver': ['saga'],\n",
    "            'model__estimator__estimator__multi_class': ['ovr'],\n",
    "            'model__estimator__estimator__random_state': [42],\n",
    "            'model__estimator__estimator__n_jobs': [-1]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": MultiOutputClassifier(RandomForestClassifier()),\n",
    "        \"param_grid\": {\n",
    "            'model__estimator__n_estimators': [1, 10, 100],\n",
    "            'model__estimator__max_depth': [1, 5, 10],\n",
    "            'model__estimator__random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": MultiOutputClassifier(GradientBoostingClassifier()),\n",
    "        \"param_grid\": {\n",
    "            \"model__estimator__n_estimators\": [10, 50, 100],\n",
    "            \"model__estimator__learning_rate\": [0.1, 0.05, 0.01],\n",
    "            \"model__estimator__max_depth\": [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'recall': make_scorer(recall_score, average='weighted', zero_division=1),\n",
    "    'f1': make_scorer(f1_score, average='weighted', zero_division=1)\n",
    "}\n",
    "\n",
    "\n",
    "# Iterate over the models and perform grid search with cross-validation\n",
    "for model_name, model_config in models.items():\n",
    "    print(f\"Training the model {model_name} using grid search with cross-validation...\")\n",
    "    \n",
    "    # Define the pipeline with preprocessing and model\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=tokenize)),\n",
    "            ('token_count', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('word_count', Pipeline([\n",
    "                ('count', WordCounter()),\n",
    "                ('scale', StandardScaler())\n",
    "            ]))\n",
    "        ])),\n",
    "        ('model', model_config['model'])\n",
    "    ])\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, \n",
    "                               param_grid=model_config[\"param_grid\"], \n",
    "                               cv=5, \n",
    "                               scoring=scoring, \n",
    "                               return_train_score=True,\n",
    "                               refit=\"f1\",\n",
    "                               verbose=1)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and its evaluation metric score\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    # Predict on the test set and evaluate the performance\n",
    "    y_pred = best_model.predict(X_validation)\n",
    "    \n",
    "    # Evaluate the overall accuracy\n",
    "    accuracy = (y_validation == y_pred).mean()\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Score: {best_score}\")\n",
    "    print(f\"Overall accuracy: {accuracy}\")\n",
    "    print(classification_report(y_validation, y_pred, target_names=y.columns, zero_division=1))\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "modelling_end_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Models sucessfully trained!\")\n",
    "print(f\"Time it took for training: {str(modelling_end_time - modelling_start_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
