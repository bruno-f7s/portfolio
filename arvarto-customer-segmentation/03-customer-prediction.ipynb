{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66676578",
   "metadata": {},
   "source": [
    "# Project Introduction - Customer Segmentation (Part 3)\n",
    "The goal of this project is to analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population with the aim of understanding which segment of the population the company should aim for in its next mail campaign. \n",
    "\n",
    "The project is divided into __three main parts__:\n",
    "1. The first part will be decicated to the data preparation: This data is high-dimensional and has a high degree of missing values, therefore it is important to understand and clean the data.\n",
    "2. In this section the customers will be segmented using a __unsupervised learning approach__ and using the customer's data against the general population's data. Not only is the goal to understand which groups of customers are more interesting for the campaign but also to select the most important features.\n",
    "3. Using the information gained a __supervised learning algorithm__ will be used for a classification task to predict which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "__Note__: This notebook handles part 3. The first part of the data cleaning process can be found in this notebook [here](https://github.com/bruno-f7s/portfolio/blob/main/arvarto-customer-segmentation/01-data-cleaning.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b578b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from joblib import dump, load\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# configurations\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb5017",
   "metadata": {},
   "source": [
    "# PART 3: Customer Segmentation (Supervised Learning)\n",
    "In this section we will use different models to train a model that predicts whether a given individual is going to be a customer or not. We will use the Mailout dataset which includes the target variable to build and test the model and at the end we will use the second dataset without the target variable to see how many individuals our customers would likely be.\n",
    "\n",
    "We will expand what we did in the second part by using the same scaler and dimensionality reduction's model to apply onto these datasets. Furthermore, we will also use the same clusters from the previous section as a new variable to add to the data. At the end, once we are applying the model onto the new data, we can analyze if the clusters which have been determined as the target groups have more positive predictions than the others.\n",
    "\n",
    "The approach looks like this:\n",
    "1.\tBrief exploratory data analysis of the distributions of the target variable.\n",
    "2.\tSplit the data into train and test sets.\n",
    "3.  Build a ml pipeline to try different models.\n",
    "4.  Evaluate the performance and chose a model.\n",
    "5.  Refit the best model onto the whole dataset.\n",
    "6.  Predict on the new data (data without the target variable).\n",
    "7.  Finalize with an analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834943c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data for the customer segmentation part\n",
    "train_df = pd.read_csv('data\\\\Cleaned_Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n",
    "test_df = pd.read_csv('data\\\\Cleaned_Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0123212c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34508, 345)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6167d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34499, 344)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472d5b6",
   "metadata": {},
   "source": [
    "# 1. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c194b3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0s: 98.7%\n",
      "Percentage of 1s: 1.3%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the counts for the reponse variable\n",
    "plt.figure(figsize = (5, 5))\n",
    "sns.countplot(data = train_df, x='RESPONSE')\n",
    "\n",
    "print(f\"Percentage of 0s: {round((len(train_df[train_df['RESPONSE'] == 0]) / len(train_df['RESPONSE']))*100, 1)}%\")\n",
    "print(f\"Percentage of 1s: {round((len(train_df[train_df['RESPONSE'] == 1]) / len(train_df['RESPONSE']))*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63147168",
   "metadata": {},
   "source": [
    "__Observation__: This dataset is extremely imbalanced. There are several ways to try and tackle this problem like undersampling the label 0 or oversampling the label 1. Between both, oversampling the label 1 would be preferable since we are not losing any information with this.\n",
    "\n",
    "In this case I will try to overcome this problem by applying more weight to the 1 class during model training and try to use a stratified cross-validation approach, which can be beneficial when dealing with imbalanced classes when comparing to the standard approach. If anything works well, then another try could be some oversampling method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1eca65",
   "metadata": {},
   "source": [
    "#### Analyse the label distribution per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdc384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the target from the rest so it can be fed into the previous models\n",
    "train_df_wo_target = train_df.drop([\"RESPONSE\"], axis=1)\n",
    "train_df_target  = train_df[\"RESPONSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18716b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scaler, pca and kmeans models\n",
    "loaded_sc = load('models\\\\population_scaler.joblib')\n",
    "loaded_pca = load('models\\\\population_pca.joblib')\n",
    "loaded_clusterer = load('models\\\\population_clusterer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef87109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using the previous models\n",
    "scaled_train_df_wo_target = loaded_sc.transform(train_df_wo_target)\n",
    "pca_train_df_wo_target = loaded_pca.transform(scaled_train_df_wo_target)\n",
    "clusters_train_df_wo_target = loaded_clusterer.predict(pca_train_df_wo_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08273d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLUSTER  RESPONSE\n",
       "0      4.0         0\n",
       "1      2.0         0\n",
       "2      2.0         0\n",
       "3      4.0         0\n",
       "4      4.0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the clusters to the scaled data and add the target variable to it\n",
    "temp_train_df = np.hstack((pca_train_df_wo_target, clusters_train_df_wo_target.reshape(-1, 1)))\n",
    "temp_train_df = pd.DataFrame(temp_train_df)\n",
    "temp_train_df = pd.concat([temp_train_df[temp_train_df.columns[-1:]], train_df_target], axis=1)\n",
    "temp_train_df = temp_train_df.rename({157: \"CLUSTER\"}, axis=1)\n",
    "temp_train_df[\"CLUSTER\"] = temp_train_df[\"CLUSTER\"] + 1\n",
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff3fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>PROPORTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1096</td>\n",
       "      <td>98.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14709</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7772</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10495</td>\n",
       "      <td>98.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLUSTER  RESPONSE  COUNT  PROPORTION\n",
       "0      1.0         0   1096        98.3\n",
       "1      1.0         1     19         1.7\n",
       "2      2.0         0  14709        98.9\n",
       "3      2.0         1    165         1.1\n",
       "4      3.0         0   7772        98.9\n",
       "5      3.0         1     88         1.1\n",
       "6      4.0         0  10495        98.5\n",
       "7      4.0         1    164         1.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Number of 0s and 1s per cluster\n",
    "count_per_category = temp_train_df.groupby(['CLUSTER', 'RESPONSE']).size().reset_index(name='COUNT')\n",
    "\n",
    "# Compute total counts per cluster\n",
    "cluster_totals = count_per_category.groupby('CLUSTER')['COUNT'].sum().reset_index(name='TOTAL_PER_CLUSTER')\n",
    "\n",
    "# Merge total counts with original dataframe\n",
    "count_per_category = count_per_category.merge(cluster_totals, on='CLUSTER', how='left')\n",
    "\n",
    "# Calculate the proportion of 0s and 1s per cluster\n",
    "count_per_category['PROPORTION'] = round(count_per_category['COUNT'] / count_per_category['TOTAL_PER_CLUSTER'] *100, 1)\n",
    "count_per_category = count_per_category.drop(\"TOTAL_PER_CLUSTER\", axis=1)\n",
    "count_per_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12a376",
   "metadata": {},
   "source": [
    "__Analysis__: We can see that the distribution of the 1 class follows a similar pattern across all clusters comparing to the whole data. \n",
    "\n",
    "In the previous part of the project, namely the customer segmentation, we saw that `cluster 4` should be the aim of the company's marketing efforts and when we look at the proportions of the 1 label in `cluster 4`, we see that it has a slightly higher proportion than `cluster 2` for instance - which is one where the customers are underrepresented comparing to the population. Altough the absolute numbers are not that high to be more sure, this is however an interesting fact towards the marketing strategy. \n",
    "\n",
    "What we can also do now is use the cluster labels as a new feature as well for the model fitting part. However we cannot just simply add it to the pca components, we first also need to scale it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c584536",
   "metadata": {},
   "source": [
    "# 2. Train-Test Split\n",
    "For this part I will just to a train-test split and not a train-test-hold-out split because the dataset is not too big, so we would have few data to do all the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7acb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a seed to be used across the pipeline\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa0d72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y variables\n",
    "X = train_df.drop([\"RESPONSE\"], axis=1)\n",
    "y = train_df[\"RESPONSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a4b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scaler, pca and kmeans models\n",
    "loaded_sc = load('models\\\\population_scaler.joblib')\n",
    "loaded_pca = load('models\\\\population_pca.joblib')\n",
    "loaded_clusterer = load('models\\\\population_clusterer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23874eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using the previous models\n",
    "scaled_X = loaded_sc.transform(X)\n",
    "pca_X = loaded_pca.transform(scaled_X)\n",
    "clusters = loaded_clusterer.predict(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d00a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the clusters to add them to the scaled_X\n",
    "cluster_scaler = StandardScaler()\n",
    "scaled_clusters = cluster_scaler.fit_transform(clusters.reshape(-1, 1))\n",
    "\n",
    "# Add the scaled clusters to the scaled_X\n",
    "scaled_X = np.hstack((pca_X, scaled_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf3e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34508, 158)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be3a1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48d84bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "Percentage of 0s: 98.7%\n",
      "Percentage of 1s: 1.3%\n",
      "-----------------------------------\n",
      "y_test\n",
      "Percentage of 0s: 98.7%\n",
      "Percentage of 1s: 1.3%\n"
     ]
    }
   ],
   "source": [
    "# Verify that the splits have the same label distribution\n",
    "print(\"y_train\")\n",
    "print(f\"Percentage of 0s: {round((len(y_train[y_train == 0]) / len(y_train))*100, 1)}%\")\n",
    "print(f\"Percentage of 1s: {round((len(y_train[y_train == 1]) / len(y_train))*100, 1)}%\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"y_test\")\n",
    "print(f\"Percentage of 0s: {round((len(y_test[y_test == 0]) / len(y_test))*100, 1)}%\")\n",
    "print(f\"Percentage of 1s: {round((len(y_test[y_test == 1]) / len(y_test))*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a906f",
   "metadata": {},
   "source": [
    "# 3. ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "871ee432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_test_model(model, X_train, X_test, y_train, y_test, cv, refit_metric, seed):\n",
    "    \"\"\"\n",
    "    DESCRIPTION\n",
    "    -----------\n",
    "    This function can be used to train and test a model for a classification problem with one target variable.\n",
    "    It uses cross-validation and grid search with the model GridSearchCV.\n",
    "    No model gets returned, but rather metric results are printed out.\n",
    "   \n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "        model (dictionray): A dictionary with the 3 elements: model of the name, model object and the parameter space.\n",
    "            Example: {\"name\": \"Logistic Regression\",\n",
    "                      \"model\": LogisticRegression(),\n",
    "                      \"param_search_space\": {'penalty': ['elasticnet'],\n",
    "                                            'l1_ratio': [0, 0.5, 1], \n",
    "                                                   'C': [1, 10, 25, 50, 100],\n",
    "                                              'solver': ['saga'],\n",
    "                                        'class_weight': ['balanced'],\n",
    "                                        'random_state': [seed],\n",
    "                                            'max_iter': [100, 200, 300, 500, 1000],\n",
    "                                              'n_jobs': [-1]\n",
    "                                            }\n",
    "                     } \n",
    "                      \n",
    "        X_train (dataframe): A dataframe with the train data of the features.\n",
    "        X_test (dataframe): A dataframe with the test data of the features.\n",
    "        y_train (dataframe): A dataframe with the train data of the target variable.\n",
    "        y_test (dataframe): A dataframe with the test data of the target variable.\n",
    "        cv (integer): The number of cross-validation folds\n",
    "        refit_metric (string): The metric to be used to calculate the best model\n",
    "        seed (integer): A value for the random_state\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "            \n",
    "    # Define the scoring metrics\n",
    "    scorers = {\n",
    "    'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "    'roc_auc': make_scorer(recall_score, average='weighted', zero_division=1),\n",
    "    'f1': make_scorer(f1_score, average='weighted', zero_division=1)\n",
    "    }\n",
    "\n",
    "    # Model Training\n",
    "    #####################################\n",
    "    print(f\"Training the model {model['name']} using GridSearchCV...\")\n",
    "    \n",
    "    # Build a grid search with cross-validation using BayesSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model[\"model\"], \n",
    "                               param_grid=model[\"param_grid\"], \n",
    "                               cv=StratifiedKFold(n_splits=cv, random_state=seed, shuffle=True), \n",
    "                               scoring=scorers, \n",
    "                               return_train_score=True,\n",
    "                               refit=refit_metric,\n",
    "                               verbose=1)\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Model Testing\n",
    "    #####################################  \n",
    "    # Predict on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    y_prob = grid_search.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Get test metrics\n",
    "    accuracy = (y_test == y_pred).mean()\n",
    "    best_model = grid_search.best_estimator_\n",
    "    cv_results = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Print Results\n",
    "    #####################################  \n",
    "    \n",
    "    # Print the overview results\n",
    "    print(f\"Model: {model['name']}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Overall Accuracy: {accuracy}\")\n",
    "    cv_results.head(len(cv_results))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "        \n",
    "    # Plot the ROC curve\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.tick_params(axis='both', labelsize=10)\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    # PLot the confusion matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "    sns.set(font_scale=1)\n",
    "    heatmap = sns.heatmap(cm, annot=True)\n",
    "    heatmap.set_xlabel(\"Predicted label\", fontsize=12)\n",
    "    heatmap.set_ylabel(\"True label\", fontsize=12)\n",
    "    heatmap.tick_params(axis='both', labelsize=10)\n",
    "    plt.show()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    \n",
    "    # Print the classication report\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(f\"Training time: {str(end_time - start_time)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d269b40",
   "metadata": {},
   "source": [
    "# 4. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7254509",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b0e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\"name\": \"Logistic Regression\",\n",
    "      \"model\": LogisticRegression(),\n",
    "      \"param_grid\": {\n",
    "          'penalty': ['elasticnet'],\n",
    "          'l1_ratio': [0, 0.5, 1], \n",
    "          'C': [1, 10, 50, 100],\n",
    "          'solver': ['saga'],\n",
    "          'class_weight': ['balanced'],\n",
    "          'random_state': [seed],\n",
    "          'max_iter': [100, 1000, 5000],\n",
    "          'n_jobs': [-1]}\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model Logistic Regression using GridSearchCV...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\bfernandes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predict_and_test_model(lr, X_train, X_test, y_train, y_test, 5, \"f1\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc18d0",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "__Observation:__ If computational power is not an issue then this can be replaced with GradientBoostingClassifier()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d59f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weights for the 1 and 0 classes\n",
    "rfc = {\n",
    "    \"name\": \"Gradient Boosting\",\n",
    "    \"model\": RandomForestClassifier(),\n",
    "    \"param_grid\": {\n",
    "        'n_estimators': [100, 250, 500, 1000], \n",
    "        'max_depth': [None, 3, 5, 7],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "        'class_weight': ['balanced_subsample'],\n",
    "        'random_state': [seed],\n",
    "        'n_jobs': [-1]\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870501fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_test_model(rfc, X_train, X_test, y_train, y_test, 5, \"f1\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6ae73",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = {\n",
    "    \"name\": \"XGBoost\",\n",
    "    \"model\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), # To prevent a warning related to label encoding\n",
    "    \"param_grid\": {\n",
    "        'n_estimators': [50, 100, 150, 200, 500], \n",
    "        'learning_rate': [0.01, 0.1, 1], \n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'alpha':[0.1, 0.25, 0.5, 0.75],\n",
    "        'subsample': [None, 0.1, 0.5, 1],\n",
    "        'random_state': [seed]\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_test_model(xgbc, X_train, X_test, y_train, y_test, 5, \"f1\", seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0367f",
   "metadata": {},
   "source": [
    "__Analysis__:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aac8f8",
   "metadata": {},
   "source": [
    "# 5. Fit the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb81b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb52240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed626b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f5a2652",
   "metadata": {},
   "source": [
    "# 6. Predict on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a706ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8692edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4644f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13eedb27",
   "metadata": {},
   "source": [
    "# 7. Analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab9463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dabd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inversed_X = sc.inverse_transform(pca.inverse_transform(pca_scaled_X[:, :-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inversed_clusters = cluster_scaler.inverse_transform(pca_scaled_X[:, -1].reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
